{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1234)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('DampedNewtonPreconditioning_images'):\n",
    "    os.makedirs('DampedNewtonPreconditioning_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To compute distance matrix\"\"\"\n",
    "def distmat(x,y):\n",
    "    return np.sum(x**2,0)[:,None] + np.sum(y**2,0)[None,:] - 2*x.transpose().dot(y)\n",
    "\n",
    "\"\"\"To Normalise a vector\"\"\"\n",
    "normalize = lambda a: a/np.sum(a)\n",
    "\n",
    "\"\"\"To Compute P\"\"\"\n",
    "def GetP(u,K,v):\n",
    "    u=u.reshape(u.shape[0],)\n",
    "    v=v.reshape(v.shape[0],)\n",
    "    return u[:,None]*K*v[None,:]\n",
    "\n",
    "def plotp(x, col,plt, scale=200, edgecolors=\"k\"):\n",
    "  return plt.scatter(x[0,:], x[1,:], s=scale, edgecolors=edgecolors,  c=col, cmap='plasma', linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=[400,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.rand(2,N[0])-0.5\n",
    "theta =2*np.pi*np.random.rand(1,N[1])\n",
    "r=0.8+.2*np.random.rand(1,N[1])\n",
    "y=np.vstack((r*np.cos(theta),r*np.sin(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import computational_OT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Sinkhorn vs damped Newton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP=[]\n",
    "results_Sinkhorn=[]\n",
    "times_Sinkhorn=[]\n",
    "epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05,0.03]\n",
    "Pmatrix_dist_linVSsinkhorn=[]\n",
    "for eps in epsilons:\n",
    "\n",
    "  \n",
    "  #Cost matrix\n",
    "  C = distmat(x,y)\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[0]))\n",
    "  a=a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[1]))\n",
    "  b=b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  #Kernel\n",
    "  K=np.exp(-C/eps)\n",
    "\n",
    "\n",
    "  print(\"Doing for (\",N[0],N[1],\").\")\n",
    "  print( \" |- Iterating\")\n",
    "\n",
    "  #Inflating\n",
    "  u=a\n",
    "  v=b\n",
    "\n",
    "  start=time.time()\n",
    "  Optimizer=computational_OT.Sinkhorn(K,a,b,u,v,eps)\n",
    "  out=Optimizer._update()\n",
    "  results_Sinkhorn.append(out)\n",
    "  end=time.time()\n",
    "  times_Sinkhorn.append(end-start)\n",
    "  print( \" |- Computing P\")\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(out[0],K,out[1]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"$||P1 -a||_1+||P1 -b||_1$\")\n",
    "for i in range(len(results_Sinkhorn)):\n",
    "  error=np.asarray(results_Sinkhorn[i][2])+np.asarray(results_Sinkhorn[i][3])\n",
    "  plt.plot( error,label='Sinkhorn for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"ConvergenceSinkhornvaryingepsilon.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Damped Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.95\n",
    "c=0.05\n",
    "DampedNewtonP=[]\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "Hessians_DampedNewton = []\n",
    "\n",
    "#epsilons=[0.05,0.08,0.1]\n",
    "# epsilons=[0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1.0 ]\n",
    "epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05,0.03]\n",
    "#epsilons=[0.3]\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print(\"Damped Newton for epsilon=\"+str(eps)+\":\")    \n",
    "    #Cost matrix\n",
    "    C = distmat(x,y)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[0]))\n",
    "    a=a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b=b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Kernel\n",
    "    K=np.exp(-C/eps)\n",
    "    f,g=a,b\n",
    "\n",
    "    print(\"Doing for (\",N[0],N[1],\").\")\n",
    "    print( \" |- Iterating\")  \n",
    "    start=time.time()\n",
    "    Optimizer=computational_OT.DampedNewton(K,a,b,f,g,eps,rho,c)\n",
    "    out=Optimizer._update(maxiter=50)\n",
    "    results_DampedNewton.append(out)\n",
    "    end=time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\")\n",
    "    \n",
    "    DampedNewtonP.append(GetP(np.exp(out[0]/eps),K,np.exp(out[1]/eps)))\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n\")\n",
    "\n",
    "    mat  = -eps*Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( np.vstack( (a,b) ) ).flatten()\n",
    "    mat = diag[:,None]*mat*diag[None,:]\n",
    "    Hessians_DampedNewton.append( mat )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  error=np.asarray(results_DampedNewton[i][2])+np.asarray(results_DampedNewton[i][3])\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ErrorLinesearchNewton.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "\n",
    "plt.title(\"Objective Function\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][4]),label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.legend()\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ObjectiveLineSearchNewton.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][5]),label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Plotting spectrum as a function of $\\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decomposition(mat):\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort(eig)\n",
    "    eig = eig[sorting_indices]\n",
    "    v   = v[:, sorting_indices]\n",
    "    \n",
    "    print( \"List of smallest eigenvalues: \", eig[:10])\n",
    "    print( \"List of largest  eigenvalues: \", eig[-10:])\n",
    "\n",
    "    return eig,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs=[]\n",
    "eigvecs=[]\n",
    "for i in range(len(epsilons)):\n",
    "    eps = epsilons[i]\n",
    "    print(\"Spectral statistics of Hessian for epsilon=\"+str(eps))\n",
    "    ev=spectral_decomposition( Hessians_DampedNewton[i] )\n",
    "    eigs.append(ev[0])\n",
    "    eigvecs.append(ev[1])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,3),nrows=1, ncols=len(epsilons), sharey=True)\n",
    "plt.title(\"Histogram of eigenvalues.\")\n",
    "for i in range(len(epsilons)):\n",
    "    ax[i].hist( eigs[i], 50)\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]))\n",
    "    ax[i].set_xlabel(\"Eigenvalues\")\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "plt.subplots_adjust(wspace=0,hspace=0)\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/eigenhistunstabilized.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Actual preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preconditioners( modified_Hessian, ansatz=True ):\n",
    "    # Diagonalize\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh( modified_Hessian )\n",
    "    sorting_indices = np.argsort(eigenvalues)\n",
    "    eigenvalues  = eigenvalues[sorting_indices]\n",
    "    eigenvectors = eigenvectors[:, sorting_indices]\n",
    "    # Form null vector\n",
    "    if not ansatz:\n",
    "        null_vector = eigenvectors[:, 0]\n",
    "    else:\n",
    "        null_vector = np.hstack( (np.ones(N[0]), -np.ones(N[1])) )\n",
    "        norm = np.sqrt( N[0] + N[1] )\n",
    "        null_vector = null_vector/norm\n",
    "    # Form other vectors (only 13)\n",
    "    n,m = eigenvectors.shape\n",
    "    indices = [m-1,1,m-2,2,m-3,3,m-4,4,m-5,5,m-6,6,m-7]\n",
    "    #indices = [m-1,1,m-2,2,m-3,3,m-4]\n",
    "    precond_vectors = eigenvectors[:, indices ]\n",
    "    precond_vectors = []\n",
    "    for index in indices:\n",
    "        precond_vectors.append( eigenvectors[:,index] )\n",
    "    #\n",
    "    return null_vector, precond_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_vector, precond_vectors = build_preconditioners( Hessians_DampedNewton[-1], ansatz=False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.95\n",
    "c=0.05\n",
    "reset_starting_point=True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP=[]\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons=[0.05,0.08,0.1]\n",
    "#precond_epsilons=[0.2, 0.3, 0.4, 0.5, 0.75, 1.0 ]\n",
    "\n",
    "precond_epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05,0.03]\n",
    "#epsilons=[0.3]\n",
    "f, g = None, None\n",
    "for eps in precond_epsilons:\n",
    "    # Line Search\n",
    "    print(\"Damped Newton for epsilon=\"+str(eps)+\":\")    \n",
    "    # Cost matrix\n",
    "    C = distmat(x,y)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[0]))\n",
    "    a = a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Kernel\n",
    "    K=np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g=a,b\n",
    "\n",
    "    print(\"Doing for (\",N[0],N[1],\").\")\n",
    "    print( \" |- Iterating\")  \n",
    "    start=time.time()\n",
    "    Optimizer=computational_OT.DampedNewton_With_Preconditioner(K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:])\n",
    "    out=Optimizer._update(maxiter=50, iterative_inversion=30, version=0,debug=False)\n",
    "    results_DampedNewton.append(out)\n",
    "    end=time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\")\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append(GetP(np.exp(out[0]/eps),K,np.exp(out[1]/eps)))\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  error=np.asarray(results_DampedNewton[i][2])+np.asarray(results_DampedNewton[i][3])\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ErrorLinesearchNewton.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "\n",
    "plt.title(\"Minus the Objective Function\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( -np.asarray(results_DampedNewton[i][4]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ObjectiveLineSearchNewton.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][5]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.95\n",
    "c=0.05\n",
    "reset_starting_point=True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP=[]\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons=[0.05,0.08,0.1]\n",
    "#precond_epsilons=[0.2, 0.3, 0.4, 0.5, 0.75, 1.0 ]\n",
    "precond_epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05]\n",
    "#epsilons=[0.3]\n",
    "f, g = None, None\n",
    "for eps in precond_epsilons:\n",
    "    # Line Search\n",
    "    print(\"Damped Newton for epsilon=\"+str(eps)+\":\")    \n",
    "    # Cost matrix\n",
    "    C = distmat(x,y)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[0]))\n",
    "    a = a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Kernel\n",
    "    K=np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g=a,b\n",
    "\n",
    "    print(\"Doing for (\",N[0],N[1],\").\")\n",
    "    print( \" |- Iterating\")  \n",
    "    start=time.time()\n",
    "    Optimizer=computational_OT.DampedNewton_With_Preconditioner(K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:])\n",
    "    out=Optimizer._update(maxiter=50, iterative_inversion=30, version=1,debug=False)\n",
    "    results_DampedNewton.append(out)\n",
    "    end=time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\")\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append(GetP(np.exp(out[0]/eps),K,np.exp(out[1]/eps)))\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  error=np.asarray(results_DampedNewton[i][2])+np.asarray(results_DampedNewton[i][3])\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ErrorLinesearchNewton.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "\n",
    "plt.title(\"Minus the Objective Function\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( -np.asarray(results_DampedNewton[i][4]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ObjectiveLineSearchNewton.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][5]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.95\n",
    "c=0.05\n",
    "reset_starting_point=True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP=[]\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons=[0.05,0.08,0.1]\n",
    "#precond_epsilons=[0.2, 0.3, 0.4, 0.5, 0.75, 1.0 ]\n",
    "precond_epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05]\n",
    "#epsilons=[0.3]\n",
    "f, g = None, None\n",
    "for eps in precond_epsilons:\n",
    "    # Line Search\n",
    "    print(\"Damped Newton for epsilon=\"+str(eps)+\":\")    \n",
    "    # Cost matrix\n",
    "    C = distmat(x,y)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[0]))\n",
    "    a = a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Kernel\n",
    "    K=np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g=a,b\n",
    "\n",
    "    print(\"Doing for (\",N[0],N[1],\").\")\n",
    "    print( \" |- Iterating\")  \n",
    "    start=time.time()\n",
    "    Optimizer=computational_OT.DampedNewton_With_Preconditioner(K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:])\n",
    "    out=Optimizer._update(maxiter=50, iterative_inversion=30, version=2,debug=False)\n",
    "    results_DampedNewton.append(out)\n",
    "    end=time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\")\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append(GetP(np.exp(out[0]/eps),K,np.exp(out[1]/eps)))\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  error=np.asarray(results_DampedNewton[i][2])+np.asarray(results_DampedNewton[i][3])\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ErrorLinesearchNewton.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "\n",
    "plt.title(\"Minus the Objective Function\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( -np.asarray(results_DampedNewton[i][4]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ObjectiveLineSearchNewton.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][5]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rho=0.95\n",
    "c=0.05\n",
    "reset_starting_point=True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP=[]\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons=[0.05,0.08,0.1]\n",
    "#precond_epsilons=[0.2, 0.3, 0.4, 0.5, 0.75, 1.0 ]\n",
    "precond_epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05]\n",
    "#epsilons=[0.3]\n",
    "f, g = None, None\n",
    "for eps in precond_epsilons:\n",
    "    # Line Search\n",
    "    print(\"Damped Newton for epsilon=\"+str(eps)+\":\")    \n",
    "    # Cost matrix\n",
    "    C = distmat(x,y)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[0]))\n",
    "    a = a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Kernel\n",
    "    K=np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g=a,b\n",
    "\n",
    "    print(\"Doing for (\",N[0],N[1],\").\")\n",
    "    print( \" |- Iterating\")  \n",
    "    start=time.time()\n",
    "    Optimizer=computational_OT.DampedNewton_With_Preconditioner(K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:])\n",
    "    out=Optimizer._update(maxiter=50, iterative_inversion=30, version=3,debug=False)\n",
    "    results_DampedNewton.append(out)\n",
    "    end=time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\")\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append(GetP(np.exp(out[0]/eps),K,np.exp(out[1]/eps)))\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  error=np.asarray(results_DampedNewton[i][2])+np.asarray(results_DampedNewton[i][3])\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ErrorLinesearchNewton.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "\n",
    "plt.title(\"Minus the Objective Function\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( -np.asarray(results_DampedNewton[i][4]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ObjectiveLineSearchNewton.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][5]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rho=0.95\n",
    "c=0.05\n",
    "reset_starting_point=True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP=[]\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons=[0.05,0.08,0.1]\n",
    "#precond_epsilons=[0.2, 0.3, 0.4, 0.5, 0.75, 1.0 ]\n",
    "precond_epsilons=[ 1.0, 0.75, 0.5, 0.4, 0.3, 0.1, 0.05]\n",
    "#epsilons=[0.3]\n",
    "f, g = None, None\n",
    "for eps in precond_epsilons:\n",
    "    # Line Search\n",
    "    print(\"Damped Newton for epsilon=\"+str(eps)+\":\")    \n",
    "    # Cost matrix\n",
    "    C = distmat(x,y)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[0]))\n",
    "    a = a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Kernel\n",
    "    K=np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g=a,b\n",
    "\n",
    "    print(\"Doing for (\",N[0],N[1],\").\")\n",
    "    print( \" |- Iterating\")  \n",
    "    start=time.time()\n",
    "    Optimizer=computational_OT.DampedNewton_With_Preconditioner(K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:])\n",
    "    out=Optimizer._update(maxiter=50, iterative_inversion=30, version=4,debug=False)\n",
    "    results_DampedNewton.append(out)\n",
    "    end=time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\")\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append(GetP(np.exp(out[0]/eps),K,np.exp(out[1]/eps)))\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  error=np.asarray(results_DampedNewton[i][2])+np.asarray(results_DampedNewton[i][3])\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ErrorLinesearchNewton.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "\n",
    "plt.title(\"Minus the Objective Function\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( -np.asarray(results_DampedNewton[i][4]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/ObjectiveLineSearchNewton.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_DampedNewton)):\n",
    "  plt.plot( np.asarray(results_DampedNewton[i][5]),label='Damped Newton for $\\epsilon=$'+ str(precond_epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"DampedNewtonPreconditioning_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. More spectral statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spectral_statistics(mat, stabilize=False):\n",
    "    if stabilize:\n",
    "        # Stabilizing largest and smallest eigenvalue\n",
    "        min_vector = np.hstack( (np.ones(N[0]), -np.ones(N[1])) )\n",
    "        max_vector = np.hstack( (np.ones(N[0]),  np.ones(N[1])) )\n",
    "        norm = np.sqrt( N[0] + N[1] )\n",
    "        min_vector = min_vector/norm\n",
    "        max_vector = max_vector/norm\n",
    "        min_vector = min_vector.reshape( (min_vector.shape[0], 1) )\n",
    "        max_vector = max_vector.reshape( (max_vector.shape[0], 1) )\n",
    "        #\n",
    "        mat = mat + np.dot( min_vector, min_vector.T)\n",
    "        mat = mat - np.dot( max_vector, max_vector.T)\n",
    "    # endif\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort(eig)\n",
    "    eig = eig[sorting_indices]\n",
    "    v   = v[:, sorting_indices]\n",
    "    \n",
    "    #print( \"Mean eigenvalue: \", np.mean(eig) )\n",
    "    print( \"List of smallest eigenvalues: \", eig[:10])\n",
    "    print( \"List of largest  eigenvalues: \", eig[-10:])\n",
    "    min_index = np.argmin(eig)\n",
    "    max_index = np.argmax(eig)\n",
    "    min_value = eig[ min_index ]\n",
    "    max_value = eig[max_index]\n",
    "    min_vector = v[:, min_index]\n",
    "    min_vector = min_vector/min_vector[0]\n",
    "    max_vector = v[:,max_index]\n",
    "    max_vector = max_vector/max_vector[0]\n",
    "    condition_number = max_value/min_value\n",
    "    # Test smallest and largest\n",
    "    # print( \"Min eigenvalue vector: \", min_vector)\n",
    "    # print( \"Max eigenvalue vector: \", max_vector)\n",
    "    #\n",
    "    #print( v[:,0]*np.sqrt( self.N1 + self.N2))\n",
    "    #vector = v[:,0]\n",
    "    #test = np.dot( result, vector)\n",
    "    #print( np.linalg.norm(test) )\n",
    "    #print(\"Min absolute eigenvalues: \", min_value)\n",
    "    #print(\"Norm of v-1: \", np.linalg.norm(min_vector-eig_vector))\n",
    "    print(\"Condition number: \", condition_number)\n",
    "    # plt.hist( eig, 50)\n",
    "    # plt.title( \"Histogram of eigenvalues for Hessian\")\n",
    "    # plt.xlabel( \"Eigenvalues\")\n",
    "    # plt.yscale( \"log\" )\n",
    "    # plt.show()\n",
    "    return eig,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs=[]\n",
    "eigvecs=[]\n",
    "for i in range(len(epsilons)):\n",
    "    eps = epsilons[i]\n",
    "    print(\"Spectral statistics of Hessian for epsilon=\"+str(eps))\n",
    "    Hessian = Hessians_DampedNewton[i]\n",
    "    ev=print_spectral_statistics( Hessian, stabilize=False)\n",
    "    eigs.append(ev[0])\n",
    "    eigvecs.append(ev[1])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the largest epsilon's eigenvectors for conditioning\n",
    "print( \"Building preconditioning eigenvectors\"  )\n",
    "#null_vector, precond_vectors = build_preconditioners( Hessians_DampedNewton[-1], ansatz=False )\n",
    "null_vector, precond_vectors = build_preconditioners( final_modified_Hessians[0], ansatz=False )\n",
    "\n",
    "for i in range(len(precond_epsilons)):\n",
    "    eps = precond_epsilons[i]\n",
    "    print(\"Spectral statistics of Hessian for epsilon=\"+str(eps))\n",
    "    Hessian = final_modified_Hessians[i]\n",
    "    print_spectral_statistics( Hessian)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the previous epsilon's eigenvectors for conditioning\n",
    "print( \"Building preconditioning eigenvectors\"  )\n",
    "null_vector, precond_vectors = build_preconditioners( Hessians_DampedNewton[-1], ansatz=False )\n",
    "\n",
    "for i in range(len(precond_epsilons)):\n",
    "    eps = precond_epsilons[i]\n",
    "    print(\"Spectral statistics of Hessian for epsilon=\"+str(eps))\n",
    "    Hessian = final_modified_Hessians[i]\n",
    "    print_spectral_statistics( Hessian)\n",
    "    print(\"\")\n",
    "    print(\"Building preconditioning eigenvectors\")\n",
    "    null_vector, precond_vectors = build_preconditioners( Hessian )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fe5188668687d60ef23f0de20cd9899503c987e11b9feb1f9c7ec2e1adfdcd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
