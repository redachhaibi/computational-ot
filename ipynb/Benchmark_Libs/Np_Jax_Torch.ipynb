{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install perfplot\n",
    "!pip install --upgrade \"jax[cpu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA GPU JAX Installation\n",
    "# !pip install --upgrade pip\n",
    "# CUDA 12 installation\n",
    "# Note: wheels only available on linux.\n",
    "# !pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NUM_THREADS = os.cpu_count()\n",
    "print( \"Number of CPU threads:\", NUM_THREADS )\n",
    "\n",
    "torch.set_num_threads( NUM_THREADS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate tests\n",
    "n = int(1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "A, B = torch.rand( n,n ), torch.rand( n, n )\n",
    "C = torch.matmul( A, B ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX\n",
    "A, B = jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ) ,jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) )\n",
    "C = jnp.dot( A, B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "A, B = np.random.rand( n, n ), np.random.rand( n, n )\n",
    "C = np.dot( A, B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfplot\n",
    "\n",
    "perfplot.show(\n",
    "    setup = lambda n: [ np.random.rand( n, n ), np.random.rand( n, n ),\n",
    "                     jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ), jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ),\n",
    "                    torch.rand( n, n ), torch.rand( n, n ) ] ,\n",
    "    kernels = [\n",
    "        lambda data: np.dot( data[0], data[1]),\n",
    "        lambda data: jnp.dot( data[2], data[3]),\n",
    "        lambda data: torch.matmul( data[4], data[5]),\n",
    "    ],\n",
    "    title = \"Matrix multiplication\",\n",
    "    labels = [ \"Numpy\", \"Jax\", \"Torch\" ],\n",
    "    n_range = [ 2 ** k for k in range(12) ],\n",
    "    xlabel = \"len(a)\",\n",
    "    equality_check = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfplot\n",
    "perfplot.show(\n",
    "    setup = lambda n: [ np.random.rand( n, n ),\n",
    "                     jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ) ,\n",
    "                    torch.rand( n, n ) ] ,\n",
    "    kernels = [\n",
    "        lambda data: np.exp( data[0] ),\n",
    "        lambda data: jnp.exp( data[1] ),\n",
    "        lambda data: torch.exp( data[2] ),\n",
    "    ],\n",
    "    title = \"Element-wise exponentiation\",\n",
    "    labels = [ \"Numpy\", \"Jax\", \"Torch\" ],\n",
    "    n_range = [ 2 ** k for k in range(12) ],\n",
    "    xlabel = \"len(a)\",\n",
    "    equality_check = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate tests first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(2e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy: SEEMS MULTITHREADED\n",
    "A, b = np.random.rand( n, n ), np.random.rand( n )\n",
    "c = scipy.sparse.linalg.cg( A, b, atol = 1e-12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jax: SEEMS MONOTHREADED\n",
    "A, b = jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ) ,jax.random.uniform( jax.random.PRNGKey(42), ( n, ) )\n",
    "c = jax.scipy.sparse.linalg.cg( A, b, atol = 1e-12 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With no limit to the number of iterative iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfplot\n",
    "perfplot.show(\n",
    "    setup = lambda n: [ np.random.rand( n, n ), np.random.rand( n ),\n",
    "                     jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ) ,jax.random.uniform( jax.random.PRNGKey(42), ( n, ) ) ], \n",
    "    kernels = [\n",
    "        lambda data: scipy.sparse.linalg.cg( data[0], data[1], atol = 1e-12 ),\n",
    "        lambda data: jax.scipy.sparse.linalg.cg( data[2], data[3], atol = 1e-12 ),\n",
    "    ],\n",
    "    title = \"Conjugate Gradient\",\n",
    "    labels = [ \"Scipy CG\", \"Jax CG\" ],\n",
    "    n_range = [ 2 ** k for k in range(12) ],\n",
    "    xlabel = \"len(a)\",\n",
    "    equality_check = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With limited iterative iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfplot\n",
    "perfplot.show(\n",
    "    setup = lambda n: [ np.random.rand( n, n ), np.random.rand( n ),\n",
    "                     jax.random.uniform( jax.random.PRNGKey(42), ( n, n ) ) ,jax.random.uniform( jax.random.PRNGKey(42), ( n, ) ) ], \n",
    "    kernels = [\n",
    "        lambda data: scipy.sparse.linalg.cg( data[0], data[1], maxiter = 30, atol = 1e-12 ),\n",
    "        lambda data: jax.scipy.sparse.linalg.cg( data[2], data[3], maxiter = 30, atol = 1e-12 ),\n",
    "    ],\n",
    "    title = \"Conjugate Gradient\",\n",
    "    labels = [ \"Scipy CG\", \"Jax CG\" ],\n",
    "    n_range = [ 2 ** k for k in range(12) ],\n",
    "    xlabel = \"len(a)\",\n",
    "    equality_check = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
